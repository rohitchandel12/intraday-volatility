{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extreme volatility considers extreme prices during a trading day to descrrbe how volatile a stock is. In this notebook, four kinds of extreme volatilities are introduced. The data used here is minute data with high, low, open and close.     \n",
    "The first three are Parkinson(1980), Garman Klass (1980) and Rogers and satchell (1991) intraday volatility. All of them have solid theory to back up. They all focus on information of every minute's high, low, open and close price. There formulas are as below:  \n",
    "Parkinson (1980):  \n",
    "$   \\begin{equation*} \\sigma = \\sqrt{\\frac{1}{4Nln2}\\sum_{i = 1}^N(ln\\frac{h_i}{l_i})^2} \\end{equation*}$  \n",
    "Garman Klass (1980):  \n",
    "$ \\begin{equation*} \\sigma = \\sqrt{\\frac{1}{N}\\sum_{i = 1}^N\\frac{1}{2}(ln\\frac{h_i}{l_i})^2 - \\frac{1}{N}\\sum_{i = 1}^N(2ln2-1)(ln\\frac{c_i}{c_{i-1}})^2}  \\end{equation*}$  \n",
    "Rogers and satchell (1991):  \n",
    "$   \\begin{equation*}  \\sigma = \\sqrt{\\frac{1}{N}\\sum_{i = 1}^N(ln\\frac{h_i}{l_i})(ln\\frac{h_i}{o_i}) + (ln\\frac{l_i}{c_{i}}) (ln\\frac{l_i}{o_{i}})}  \\end{equation*}$  \n",
    "In all formulas $h_i$, $l_i$, $cl_i$,$o_i$ are high, low, close and open prices for interval i respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The last intraday volatility is self-defined, which employs trading experience of my own. When observating intraday performance of a stock, people are likely to notice several local high and local low points. Between two continuous local extreme points, there are local trends, which describe how volatile a stock is in short term. For stocks with the same highest price and lowest price of a day, the more short-term trends a stock has, the more severe every short-term trend is, the more volatile a stock should be in a day. According to this observation, I constructed the last metric, which is also similar to metrics described above:  \n",
    "$   \\begin{equation*} \\sigma = \\sqrt{\\sum_{j = 1}^N(ln\\frac{extreme_j}{extreme_{j-1}})^2} \\end{equation*}$    \n",
    "where $extreme_j$ denotes the local extreme values of a stock close price trend during a day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a class defined to find peak points(local extreme points) \n",
    "class peak(object):\n",
    "#==============================================================================\n",
    "#find peak points of time series\n",
    "#peak points decided when two ma lines meet\n",
    "#MA_length1, MA_length2: window length of two ma   lines\n",
    "#last: last price of 1 period\n",
    "#==============================================================================\n",
    "\n",
    "    def __init__(self,MA_length1,MA_length2):\n",
    "        self.last=np.array([])\n",
    "        self.n1=MA_length1\n",
    "        self.n2=MA_length2\n",
    "        self.n3=max(self.n1,self.n2)\n",
    "        self.MA_1=[]\n",
    "        self.MA_2=[]\n",
    "        self.section_dict=[(0,'None')]\n",
    "        self.diff=[0]*(self.n3-1)\n",
    "        #index of effective peak points\n",
    "        self.min_peak=[]\n",
    "        self.max_peak=[]\n",
    "        #index of all peak points\n",
    "        self.min_peak_all=[]\n",
    "        self.max_peak_all=[]\n",
    "        \n",
    "        self.min_now=[]\n",
    "        self.max_now=[]\n",
    "        self.latest_peak = \"None\"\n",
    "        self.trend_inc=[]\n",
    "        self.trend_dec=[]\n",
    "\n",
    "    def find_peak(self,data):\n",
    "        temp=data\n",
    "        self.last=np.append(self.last,temp)\n",
    "        self.current_wave=(self.last.max()/self.last.min()-1)\n",
    "        \n",
    "        if len(self.last)>=max(self.n1,self.n2):\n",
    "            self.MA_1.append(self.last[-self.n1:].mean())\n",
    "            self.MA_2.append(self.last[-self.n2:].mean())\n",
    "            self.diff.append(self.MA_1[-1]-self.MA_2[-1])\n",
    "        else:\n",
    "            self.MA_1.append(self.last[-1])\n",
    "            self.MA_2.append(self.last[-1])\n",
    "           \n",
    "        if len(self.last) <= self.n3:\n",
    "            self.min_now.append(np.argmin(self.last.min()))\n",
    "            self.max_now.append(np.argmax(self.last.max()))\n",
    "            self.trend_inc.append(0)\n",
    "            self.trend_dec.append(0)\n",
    "\n",
    "        if len(self.last) > self.n3:\n",
    "            if self.diff[-1]==0:\n",
    "                self.diff[-1]=self.diff[-2]\n",
    "            \n",
    "            if self.diff[-1]>0 and self.diff[-1]*self.diff[-2]<0 and self.latest_peak != \"min\":\n",
    "                self.section_dict.append((len(self.diff)-1,'min'))\n",
    "                start=self.section_dict[-2][0]\n",
    "                end=self.section_dict[-1][0]\n",
    "                self.min_peak_all.append(start+np.argmin(self.last[start:end]))                   \n",
    "                last_three = [self.last[self.max_now[-1]],self.last[start:end].min(),self.last[self.min_now[-1]]]\n",
    "                if max(last_three)/min(last_three)<1+self.current_wave/10:\n",
    "                    if len(self.max_peak)>0: del self.max_peak[-1]\n",
    "                    if self.last[self.min_now[-1]]>self.last[start:end].min() and len(self.min_peak)>0:\n",
    "                        self.min_peak[-1] = start+np.argmin(self.last[start:end])\n",
    "                else:\n",
    "                    self.min_peak.append(start+np.argmin(self.last[start:end]))\n",
    "                self.latest_peak = \"min\"                       \n",
    "                if len(self.min_peak)>0: self.min_now.append(self.min_peak[-1])\n",
    "                else: self.min_now.append(self.min_now[-1])\n",
    "                if len(self.max_peak)>0: self.max_now.append(self.max_peak[-1])\n",
    "                else: self.max_now.append(self.max_now[-1])\n",
    "\n",
    "                \n",
    "            elif self.diff[-1]<0 and self.diff[-1]*self.diff[-2]<0 and self.latest_peak != \"max\" :\n",
    "                self.section_dict.append((len(self.diff)-1,'max'))\n",
    "                start=self.section_dict[-2][0]\n",
    "                end=self.section_dict[-1][0]\n",
    "                self.max_peak_all.append(start+np.argmax(self.last[start:end]))\n",
    "                last_three = [self.last[self.max_now[-1]],self.last[start:end].max(),self.last[self.min_now[-1]]]\n",
    "                if max(last_three)/min(last_three)<1.0016:     \n",
    "                    if len(self.min_peak)>0: del self.min_peak[-1]\n",
    "                    if self.last[self.max_now[-1]]<self.last[start:end].max() and len(self.max_peak)>0:\n",
    "                        self.max_peak[-1] = start+np.argmax(self.last[start:end])\n",
    "                else:\n",
    "                    self.max_peak.append(start+np.argmax(self.last[start:end]))\n",
    "                self.latest_peak = \"max\"                       \n",
    "                if len(self.min_peak)>0: self.min_now.append(self.min_peak[-1])\n",
    "                else: self.min_now.append(self.min_now[-1])\n",
    "                if len(self.max_peak)>0: self.max_now.append(self.max_peak[-1])\n",
    "                else: self.max_now.append(self.max_now[-1])\n",
    "                \n",
    "            else:\n",
    "                self.min_now.append(self.min_now[-1])\n",
    "                self.max_now.append(self.max_now[-1])\n",
    "\n",
    "            if len(self.min_peak)>2:             \n",
    "#                self.trend_inc.append((self.last[self.min_peak[-1]]-self.last[self.min_peak[-2]])/(self.last[self.min_peak[-2]])/((self.min_peak[-1]-self.min_peak[-2])))\n",
    "                self.trend_inc.append((self.last[self.min_peak[-1]]-self.last[self.min_peak[-2]])/(self.last[self.min_peak[-2]]))                \n",
    "            else: self.trend_inc.append(0)\n",
    "            if len(self.max_peak)>2:\n",
    "#                self.trend_dec.append((self.last[self.max_peak[-1]]-self.last[self.max_peak[-2]])/(self.last[self.max_peak[-2]])/((self.max_peak[-1]-self.max_peak[-2])))\n",
    "                self.trend_dec.append((self.last[self.max_peak[-1]]-self.last[self.max_peak[-2]])/(self.last[self.max_peak[-2]]))\n",
    "            else:self.trend_dec.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak(stock_data,ma_1=5,ma_2=10):\n",
    "    peak_data=peak(ma_1,ma_2)\n",
    "    for index in range(len(stock_data)):\n",
    "        minute_data=pd.DataFrame(stock_data.iloc[index]).T\n",
    "        peak_data.find_peak(minute_data.close)\n",
    "    return peak_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see the effect of the local extreme points finding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=os.path.join((os.getcwd())[:-9],'data')\n",
    "trade_list=os.listdir(path)\n",
    "\n",
    "#choose 1 dataset as an example\n",
    "object_stock=trade_list[10]\n",
    "temp_data=pd.read_csv(os.path.join(path,object_stock))\n",
    "temp_data.timestamp=temp_data.timestamp.apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(x)))\n",
    "temp_data.set_index('timestamp',inplace=True)\n",
    "temp_data=temp_data[temp_data.volume!=0]\n",
    "temp_data.dropna(how='any',inplace=True)\n",
    "peak_data=find_peak(temp_data)\n",
    "data=peak_data.last\n",
    "arr_section=np.array(peak_data.section_dict[:])[:,0].astype('int')\n",
    "\n",
    "last_data=go.Scatter(x=list(range(len(data))),y=data,mode='lines',name='last_price')\n",
    "#build up compare data\n",
    "max_point=data.argmax()\n",
    "min_point=data.argmin()\n",
    "compare_index=[0,min(max_point,min_point),max(max_point,min_point),len(data)-1]\n",
    "compare_data=data[compare_index]\n",
    "compare_data=go.Scatter(x=compare_index,y=compare_data,mode='lines',name='simulate_price')\n",
    "peak_min_data=go.Scatter(x=peak_data.min_peak_all,y=data[peak_data.min_peak_all],mode='markers',name='peak_min',marker=dict(size=20,color='green'))\n",
    "peak_max_data=go.Scatter(x=peak_data.max_peak_all,y=data[peak_data.max_peak_all],mode='markers',name='peak_max',marker=dict(size=20,color='red'))\n",
    "#section=go.Scatter(x=arr_section,y=data[arr_section],mode='markers',name='section',marker=dict(size=20,color='black',symbol='cross'))\n",
    "layout=go.Layout(title=object_stock[:-4])\n",
    "#data_plot=[last_data,peak_min_data,peak_max_data,section]\n",
    "data_plot=[last_data,peak_min_data,peak_max_data,compare_data]\n",
    "fig=go.Figure(data=data_plot,layout=layout)\n",
    "plt.plot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new window, we can see the minute close price trend of CAT on 23rd, May, 2019. Red points denote local high point the code finds and green points denote local low points. Compared to the simulated price denotes in red line, even though the highest and lowest price of the day are the same, real price is more volatile because of the exsitence of short-term trends, located between two continuous extreme points.  \n",
    "The following part is to calculate four metrics of extreme volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_vol=pd.DataFrame(columns=['Parkinson','Garman_Klass','Rogers_Satchell','local_peak_vol'])\n",
    "for object_stock in trade_list:\n",
    "    temp_data=pd.read_csv(os.path.join(path,object_stock))\n",
    "    temp_data.timestamp=temp_data.timestamp.apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(x)))\n",
    "    temp_data.set_index('timestamp',inplace=True)\n",
    "    temp_data=temp_data[temp_data.volume!=0]\n",
    "    temp_data.dropna(how='any',inplace=True)\n",
    "\n",
    "    #parkinson ,Garman_Klass, Rogers_Satchell extreme vol\n",
    "    part1=(np.log(temp_data.high/temp_data.low)**2).sum()\n",
    "    extreme_vol.loc[object_stock[:-7],'Parkinson']=(part1/(4*len(temp_data.high)*np.log(2)))**0.5\n",
    "\n",
    "    part1=(np.log((temp_data.high/temp_data.low).iloc[1:])**2).sum()\n",
    "    part2=(2*np.log(2)-1)*(np.log((temp_data.close/temp_data.close.shift()).iloc[1:])**2).sum()\n",
    "    extreme_vol.loc[object_stock[:-7],'Garman_Klass']=((part1/2-part2)/len(temp_data.high))**0.5\n",
    "\n",
    "    extreme_vol.loc[object_stock[:-7],'Rogers_Satchell']=(((np.log(temp_data.high/temp_data.low)*np.log(temp_data.high/temp_data.open)+np.log(temp_data.low/temp_data.close)*np.log(temp_data.low/temp_data.open)).sum())/len(temp_data.high))**0.5\n",
    "\n",
    "    #find local extreme data\n",
    "    peak_data=find_peak(temp_data)\n",
    "    #combine all the local extreme index\n",
    "    index_all=[0]+peak_data.min_peak+peak_data.max_peak+[len(peak_data.last)-1]\n",
    "    index_all.sort()\n",
    "    extreme_value=peak_data.last[index_all]\n",
    "    extreme_vol.loc[object_stock[:-7],'local_peak_vol']=np.sqrt((np.diff(np.log(list(extreme_value)))**2).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataframe shows the calculated number of four metrics of different stocks on different date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Parkinson Garman_Klass Rogers_Satchell local_peak_vol\n",
      "TRV_2019-05-28   0.000283762  0.000236233     0.000376184      0.0128039\n",
      "MMM_2019-05-28   0.000356989  0.000331983     0.000458151      0.0128056\n",
      "MMM_2019-05-24   0.000473722  0.000447043       0.0006702      0.0136502\n",
      "MSFT_2019-05-29  0.000541447  0.000520891     0.000748425      0.0174715\n",
      "TRV_2019-05-24   0.000278438  0.000238676     0.000367571       0.010566\n",
      "MCD_2019-05-23   0.000307933  0.000267885     0.000413383      0.0124092\n",
      "VZ_2019-05-29    0.000470771  0.000430031     0.000649193      0.0165103\n",
      "AXP_2019-05-23   0.000382019  0.000340742     0.000522184      0.0146665\n",
      "INTC_2019-05-28  0.000715759  0.000681806     0.000945222       0.033675\n",
      "INTC_2019-05-24  0.000559615  0.000528001      0.00076548      0.0173916\n",
      "CAT_2019-05-23   0.000657662  0.000574821     0.000913742       0.023919\n",
      "PG_2019-05-29    0.000406488  0.000349323     0.000558017      0.0158274\n",
      "WMT_2019-05-24   0.000328471  0.000300579     0.000459322      0.0115512\n",
      "GS_2019-05-24    0.000414599  0.000378927     0.000551969       0.014068\n",
      "GS_2019-05-28    0.000440801   0.00038527     0.000594745      0.0158109\n",
      "WMT_2019-05-28   0.000371046  0.000344502     0.000514816      0.0119647\n",
      "V_2019-05-24     0.000372356  0.000329138     0.000506174       0.010874\n",
      "V_2019-05-28     0.000402052  0.000380815     0.000564461      0.0162604\n",
      "PFE_2019-05-23   0.000487831  0.000478621     0.000663368      0.0151216\n",
      "CSCO_2019-05-29  0.000618578  0.000561799      0.00081651      0.0185098\n",
      "UTX_2019-05-23   0.000757257  0.000653759      0.00104427      0.0309961\n",
      "DWDP_2019-05-29  0.000736624  0.000672925      0.00104228      0.0296189\n",
      "NKE_2019-05-29    0.00068929  0.000588814     0.000894329      0.0262249\n",
      "KO_2019-05-29    0.000439997  0.000378908      0.00062676      0.0145437\n",
      "BA_2019-05-29    0.000617766  0.000566789     0.000814167      0.0201795\n",
      "CVX_2019-05-24   0.000411689  0.000379305      0.00056057      0.0164394\n",
      "JPM_2019-05-29   0.000484297  0.000451119     0.000675072      0.0198867\n",
      "CVX_2019-05-28   0.000392298  0.000343105     0.000524432      0.0132213\n",
      "XOM_2019-05-23   0.000413013  0.000397981     0.000571984      0.0121588\n",
      "IBM_2019-05-23   0.000450437  0.000400315     0.000570209      0.0263926\n",
      "...                      ...          ...             ...            ...\n",
      "JNJ_2019-05-29    0.00092764  0.000842227       0.0011708      0.0485862\n",
      "MMM_2019-05-23   0.000554779  0.000538974     0.000743553      0.0209882\n",
      "TRV_2019-05-23      0.000331  0.000260958     0.000438493       0.014613\n",
      "MCD_2019-05-24   0.000263222  0.000222031      0.00034033      0.0125468\n",
      "AXP_2019-05-24   0.000310094  0.000277117     0.000396374       0.010134\n",
      "AXP_2019-05-28   0.000317798  0.000278751     0.000435952      0.0116785\n",
      "INTC_2019-05-23  0.000749509  0.000725677      0.00106306      0.0287418\n",
      "MCD_2019-05-28   0.000267866  0.000242368     0.000368827      0.0111309\n",
      "CAT_2019-05-24   0.000472825   0.00041956     0.000618762      0.0158675\n",
      "WMT_2019-05-23   0.000494946  0.000517537     0.000733723      0.0145571\n",
      "GS_2019-05-23    0.000537086  0.000507408     0.000714082      0.0241134\n",
      "CAT_2019-05-28   0.000501489  0.000471053     0.000664267      0.0149673\n",
      "UTX_2019-05-28   0.000491047  0.000429193      0.00067408      0.0200692\n",
      "V_2019-05-23     0.000465264  0.000425925     0.000627542      0.0170626\n",
      "PFE_2019-05-28   0.000490676  0.000456519     0.000663569      0.0166717\n",
      "PFE_2019-05-24   0.000380749   0.00037257     0.000525103      0.0129072\n",
      "UTX_2019-05-24   0.000527668  0.000448778     0.000725411      0.0202474\n",
      "WBA_2019-05-29   0.000527174  0.000469996     0.000701749      0.0239891\n",
      "UNH_2019-05-29   0.000733596  0.000633804     0.000990386      0.0241648\n",
      "CVX_2019-05-23    0.00039221  0.000366853      0.00053348      0.0112596\n",
      "XOM_2019-05-28   0.000420404  0.000373081     0.000524894      0.0157347\n",
      "XOM_2019-05-24   0.000351628  0.000339533     0.000472376      0.0140617\n",
      "DIS_2019-05-28   0.000372208  0.000353437     0.000496952      0.0127843\n",
      "AAPL_2019-05-28  0.000681365  0.000626792     0.000918183      0.0189875\n",
      "IBM_2019-05-24   0.000447403  0.000380653     0.000573179      0.0144561\n",
      "HD_2019-05-23    0.000669405  0.000632092     0.000905757      0.0282696\n",
      "MRK_2019-05-23   0.000424276  0.000394148     0.000582441      0.0144172\n",
      "DIS_2019-05-24   0.000335523  0.000319143       0.0004499      0.0105442\n",
      "IBM_2019-05-28   0.000391882  0.000315589     0.000498842      0.0153194\n",
      "AAPL_2019-05-24  0.000520064  0.000510168     0.000715191      0.0172109\n",
      "\n",
      "[120 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extreme_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parkinson</th>\n",
       "      <th>Garman_Klass</th>\n",
       "      <th>Rogers_Satchell</th>\n",
       "      <th>local_peak_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parkinson</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985847</td>\n",
       "      <td>0.992554</td>\n",
       "      <td>0.872398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garman_Klass</th>\n",
       "      <td>0.985847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985662</td>\n",
       "      <td>0.837739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rogers_Satchell</th>\n",
       "      <td>0.992554</td>\n",
       "      <td>0.985662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_peak_vol</th>\n",
       "      <td>0.872398</td>\n",
       "      <td>0.837739</td>\n",
       "      <td>0.844956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parkinson  Garman_Klass  Rogers_Satchell  local_peak_vol\n",
       "Parkinson         1.000000      0.985847         0.992554        0.872398\n",
       "Garman_Klass      0.985847      1.000000         0.985662        0.837739\n",
       "Rogers_Satchell   0.992554      0.985662         1.000000        0.844956\n",
       "local_peak_vol    0.872398      0.837739         0.844956        1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_vol.astype(\"float\").corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation of four metrics, we can also find they are highly correlated, which proves that they can catch similarities of intraday volatilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://eranraviv.com/intraday-volatility-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
